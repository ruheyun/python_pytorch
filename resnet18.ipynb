{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPnlGsuQ2+rbgnYpQwZc/i+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruheyun/python_pytorch/blob/main/resnet18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9bMreez2a4e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#定义残差块ResBlock\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, inchannel, outchannel, stride=1):\n",
        "        super(ResBlock, self).__init__()\n",
        "        #这里定义了残差块内连续的2个卷积层\n",
        "        self.left = nn.Sequential(\n",
        "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(outchannel),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(outchannel)\n",
        "        )\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or inchannel != outchannel:\n",
        "            #shortcut，这里为了跟2个卷积层的结果结构一致，要做处理\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(outchannel)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.left(x)\n",
        "        #将2个卷积层的输出跟处理过的x相加，实现ResNet的基本结构\n",
        "        out = out + self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "NNhjMT8Y2lKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.inchannel = 64\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            # nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "        self.layer1 = self.make_layer(ResBlock, 64, 2, stride=1)\n",
        "        self.layer2 = self.make_layer(ResBlock, 128, 2, stride=2)\n",
        "        self.layer3 = self.make_layer(ResBlock, 256, 2, stride=2)\n",
        "        self.layer4 = self.make_layer(ResBlock, 512, 2, stride=2)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "    #这个函数主要是用来，重复同一个残差块\n",
        "    def make_layer(self, block, channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.inchannel, channels, stride))\n",
        "            self.inchannel = channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #在这里，整个ResNet18的结构就很清晰了\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        # out = F.avg_pool2d(out, 7)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "3_W7oAiZ2mMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from resnet import ResNet18\n",
        "#Use the ResNet18 on Cifar-10\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#check gpu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#set hyperparameter\n",
        "EPOCH = 20\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "#prepare dataset and preprocessing\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=2),\n",
        "    # transforms.Resize(244),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    # transforms.Resize(244),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "#labels in CIFAR10\n",
        "# classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "#define ResNet18\n",
        "net = ResNet().to(device)\n",
        "\n",
        "#define loss funtion & optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=1e-2, momentum=9e-1, weight_decay=5e-4)\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "EdQkP0Tu2pZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "for epoch in range(EPOCH):\n",
        "    print('\\nEpoch: %d' % (epoch + 1))\n",
        "    net.train()\n",
        "    sum_loss = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    for i, data in enumerate(trainloader):\n",
        "        #prepare dataset\n",
        "        length = len(trainloader)\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #forward & backward\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #print ac & loss in each batch\n",
        "        sum_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        if i % 100 == 0:\n",
        "          print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% '\n",
        "              % (epoch + 1, i, sum_loss / (i + 1), 100. * correct / total))\n",
        "\n",
        "    #get the ac with testdataset in each epoch\n",
        "    print('Waiting Test...')\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        print('Test\\'s ac is: %.3f%%' % (100 * correct / total))\n",
        "\n",
        "print('Train has finished, total epoch is %d' % EPOCH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWBoyUIZ2xQH",
        "outputId": "4c33d5de-11c0-4e67-e38e-704e6326da74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1\n",
            "[epoch:1, iter:0] Loss: 2.367 | Acc: 10.938% \n",
            "[epoch:1, iter:100] Loss: 1.774 | Acc: 34.615% \n",
            "[epoch:1, iter:200] Loss: 1.602 | Acc: 40.695% \n",
            "[epoch:1, iter:300] Loss: 1.490 | Acc: 45.035% \n",
            "Waiting Test...\n",
            "Test's ac is: 51.210%\n",
            "\n",
            "Epoch: 2\n",
            "[epoch:2, iter:0] Loss: 1.111 | Acc: 58.594% \n",
            "[epoch:2, iter:100] Loss: 1.002 | Acc: 64.550% \n",
            "[epoch:2, iter:200] Loss: 0.970 | Acc: 65.621% \n",
            "[epoch:2, iter:300] Loss: 0.933 | Acc: 66.967% \n",
            "Waiting Test...\n",
            "Test's ac is: 70.930%\n",
            "\n",
            "Epoch: 3\n",
            "[epoch:3, iter:0] Loss: 0.804 | Acc: 70.312% \n",
            "[epoch:3, iter:100] Loss: 0.744 | Acc: 74.149% \n",
            "[epoch:3, iter:200] Loss: 0.721 | Acc: 74.891% \n",
            "[epoch:3, iter:300] Loss: 0.712 | Acc: 75.293% \n",
            "Waiting Test...\n",
            "Test's ac is: 71.930%\n",
            "\n",
            "Epoch: 4\n",
            "[epoch:4, iter:0] Loss: 0.549 | Acc: 81.250% \n",
            "[epoch:4, iter:100] Loss: 0.592 | Acc: 79.386% \n",
            "[epoch:4, iter:200] Loss: 0.586 | Acc: 79.614% \n",
            "[epoch:4, iter:300] Loss: 0.577 | Acc: 79.939% \n",
            "Waiting Test...\n",
            "Test's ac is: 80.610%\n",
            "\n",
            "Epoch: 5\n",
            "[epoch:5, iter:0] Loss: 0.556 | Acc: 81.250% \n",
            "[epoch:5, iter:100] Loss: 0.519 | Acc: 82.109% \n",
            "[epoch:5, iter:200] Loss: 0.511 | Acc: 82.206% \n",
            "[epoch:5, iter:300] Loss: 0.502 | Acc: 82.498% \n",
            "Waiting Test...\n",
            "Test's ac is: 81.450%\n",
            "\n",
            "Epoch: 6\n",
            "[epoch:6, iter:0] Loss: 0.414 | Acc: 85.938% \n",
            "[epoch:6, iter:100] Loss: 0.431 | Acc: 84.940% \n",
            "[epoch:6, iter:200] Loss: 0.446 | Acc: 84.371% \n",
            "[epoch:6, iter:300] Loss: 0.442 | Acc: 84.546% \n",
            "Waiting Test...\n",
            "Test's ac is: 84.070%\n",
            "\n",
            "Epoch: 7\n",
            "[epoch:7, iter:0] Loss: 0.458 | Acc: 82.031% \n",
            "[epoch:7, iter:100] Loss: 0.397 | Acc: 86.115% \n",
            "[epoch:7, iter:200] Loss: 0.391 | Acc: 86.361% \n",
            "[epoch:7, iter:300] Loss: 0.391 | Acc: 86.412% \n",
            "Waiting Test...\n",
            "Test's ac is: 85.940%\n",
            "\n",
            "Epoch: 8\n",
            "[epoch:8, iter:0] Loss: 0.278 | Acc: 92.188% \n",
            "[epoch:8, iter:100] Loss: 0.359 | Acc: 87.330% \n",
            "[epoch:8, iter:200] Loss: 0.354 | Acc: 87.446% \n",
            "[epoch:8, iter:300] Loss: 0.361 | Acc: 87.425% \n",
            "Waiting Test...\n",
            "Test's ac is: 85.520%\n",
            "\n",
            "Epoch: 9\n",
            "[epoch:9, iter:0] Loss: 0.277 | Acc: 92.188% \n",
            "[epoch:9, iter:100] Loss: 0.319 | Acc: 89.008% \n",
            "[epoch:9, iter:200] Loss: 0.318 | Acc: 89.047% \n",
            "[epoch:9, iter:300] Loss: 0.322 | Acc: 88.933% \n",
            "Waiting Test...\n",
            "Test's ac is: 83.110%\n",
            "\n",
            "Epoch: 10\n",
            "[epoch:10, iter:0] Loss: 0.268 | Acc: 91.406% \n",
            "[epoch:10, iter:100] Loss: 0.292 | Acc: 89.643% \n",
            "[epoch:10, iter:200] Loss: 0.295 | Acc: 89.595% \n",
            "[epoch:10, iter:300] Loss: 0.297 | Acc: 89.579% \n",
            "Waiting Test...\n",
            "Test's ac is: 84.230%\n",
            "\n",
            "Epoch: 11\n",
            "[epoch:11, iter:0] Loss: 0.170 | Acc: 92.969% \n",
            "[epoch:11, iter:100] Loss: 0.260 | Acc: 90.981% \n",
            "[epoch:11, iter:200] Loss: 0.265 | Acc: 90.734% \n",
            "[epoch:11, iter:300] Loss: 0.269 | Acc: 90.651% \n",
            "Waiting Test...\n",
            "Test's ac is: 86.820%\n",
            "\n",
            "Epoch: 12\n",
            "[epoch:12, iter:0] Loss: 0.136 | Acc: 95.312% \n",
            "[epoch:12, iter:100] Loss: 0.232 | Acc: 91.847% \n",
            "[epoch:12, iter:200] Loss: 0.236 | Acc: 91.690% \n",
            "[epoch:12, iter:300] Loss: 0.250 | Acc: 91.276% \n",
            "Waiting Test...\n",
            "Test's ac is: 86.380%\n",
            "\n",
            "Epoch: 13\n",
            "[epoch:13, iter:0] Loss: 0.332 | Acc: 85.938% \n",
            "[epoch:13, iter:100] Loss: 0.223 | Acc: 92.226% \n",
            "[epoch:13, iter:200] Loss: 0.227 | Acc: 92.098% \n",
            "[epoch:13, iter:300] Loss: 0.229 | Acc: 91.993% \n",
            "Waiting Test...\n",
            "Test's ac is: 88.520%\n",
            "\n",
            "Epoch: 14\n",
            "[epoch:14, iter:0] Loss: 0.237 | Acc: 89.844% \n",
            "[epoch:14, iter:100] Loss: 0.204 | Acc: 92.806% \n",
            "[epoch:14, iter:200] Loss: 0.215 | Acc: 92.491% \n",
            "[epoch:14, iter:300] Loss: 0.211 | Acc: 92.670% \n",
            "Waiting Test...\n",
            "Test's ac is: 88.940%\n",
            "\n",
            "Epoch: 15\n",
            "[epoch:15, iter:0] Loss: 0.203 | Acc: 92.969% \n",
            "[epoch:15, iter:100] Loss: 0.180 | Acc: 93.657% \n",
            "[epoch:15, iter:200] Loss: 0.189 | Acc: 93.369% \n",
            "[epoch:15, iter:300] Loss: 0.194 | Acc: 93.210% \n",
            "Waiting Test...\n",
            "Test's ac is: 89.310%\n",
            "\n",
            "Epoch: 16\n",
            "[epoch:16, iter:0] Loss: 0.146 | Acc: 96.875% \n",
            "[epoch:16, iter:100] Loss: 0.166 | Acc: 93.998% \n",
            "[epoch:16, iter:200] Loss: 0.172 | Acc: 93.972% \n",
            "[epoch:16, iter:300] Loss: 0.174 | Acc: 93.841% \n",
            "Waiting Test...\n",
            "Test's ac is: 88.580%\n",
            "\n",
            "Epoch: 17\n",
            "[epoch:17, iter:0] Loss: 0.141 | Acc: 94.531% \n",
            "[epoch:17, iter:100] Loss: 0.165 | Acc: 94.214% \n",
            "[epoch:17, iter:200] Loss: 0.170 | Acc: 93.921% \n",
            "[epoch:17, iter:300] Loss: 0.170 | Acc: 93.947% \n",
            "Waiting Test...\n",
            "Test's ac is: 89.730%\n",
            "\n",
            "Epoch: 18\n",
            "[epoch:18, iter:0] Loss: 0.113 | Acc: 95.312% \n",
            "[epoch:18, iter:100] Loss: 0.140 | Acc: 95.150% \n",
            "[epoch:18, iter:200] Loss: 0.151 | Acc: 94.702% \n",
            "[epoch:18, iter:300] Loss: 0.151 | Acc: 94.780% \n",
            "Waiting Test...\n",
            "Test's ac is: 88.930%\n",
            "\n",
            "Epoch: 19\n",
            "[epoch:19, iter:0] Loss: 0.249 | Acc: 92.188% \n",
            "[epoch:19, iter:100] Loss: 0.141 | Acc: 94.879% \n",
            "[epoch:19, iter:200] Loss: 0.143 | Acc: 94.862% \n",
            "[epoch:19, iter:300] Loss: 0.142 | Acc: 94.858% \n",
            "Waiting Test...\n",
            "Test's ac is: 89.890%\n",
            "\n",
            "Epoch: 20\n",
            "[epoch:20, iter:0] Loss: 0.070 | Acc: 96.875% \n",
            "[epoch:20, iter:100] Loss: 0.120 | Acc: 95.746% \n",
            "[epoch:20, iter:200] Loss: 0.123 | Acc: 95.651% \n",
            "[epoch:20, iter:300] Loss: 0.129 | Acc: 95.455% \n",
            "Waiting Test...\n",
            "Test's ac is: 89.810%\n",
            "Train has finished, total epoch is 20\n"
          ]
        }
      ]
    }
  ]
}